# 4. System Design Patterns

This document outlines the key software design patterns that will be used to implement the system architecture.

## 1. Core Application Patterns

### 1.1. Singleton Pattern

-   **Component:** `Config Manager`
-   **Reasoning:** We need a single, globally accessible point for all configuration data. The Singleton pattern ensures that we only load the configuration files from disk once and that all modules (Scraper, ADK Workflow, Notifier) receive the exact same configuration state. This prevents redundancy and ensures consistency.
-   **Implementation:** We will create a `Config` class with a class method `get_instance()` that creates a single, cached instance of itself on first call and returns that same instance on all subsequent calls.

### 1.2. Pipeline Pattern

-   **Component:** `Orchestrator` and `ADK Workflow`
-   **Reasoning:** Our entire process is a sequence of distinct steps where the output of one step becomes the input for the next (Scrape -> Validate -> Generate -> Review -> Notify). The Pipeline pattern is a natural fit for this linear flow. It allows us to process a stream of data (jobs) through a series of modular stages.
-   **Implementation:** The `Orchestrator` will act as the pipeline driver, calling each major module in sequence. Within the ADK, we will use a `Sequential` agent to chain the individual AI agents together, formalizing the pipeline structure.

### 1.3. Adapter Pattern

-   **Component:** `Telegram Notifier`
-   **Reasoning:** We want to decouple our application's core logic from the specific implementation details of the Telegram API. The Adapter pattern will wrap the `requests` library calls to the Telegram API, exposing a simple, clean method like `notifier.send(message)`. If we ever decide to switch to a different notification service (e.g., Discord or Slack), we only have to change this adapter, not the orchestrator.

## 2. Agent & Workflow Patterns

### 2.1. Chain of Responsibility Pattern

-   **Component:** `ADK Workflow` (Job Validation -> Content Generation -> Content Review)
-   **Reasoning:** This pattern is a more specific implementation of our pipeline. Each agent in the workflow has a specific responsibility. It processes the data it receives and then passes the result along to the next agent in the chain. This creates a loosely coupled system where each agent only needs to know about its immediate successor.
-   **Implementation:** We will use the Google ADK's `Sequential` agent orchestrator, which is a direct implementation of this pattern.

### 2.2. Strategy Pattern

-   **Component:** `Scraping Module` (Conceptual)
-   **Reasoning:** While we are only implementing a LinkedIn scraper initially, our architecture should be open to extension. The Strategy pattern allows us to define a common interface for "scraping" (e.g., a `Scraper` abstract base class with a `scrape()` method). We can then create a concrete `LinkedInScraper` implementation. If we later want to add an Indeed scraper, we can simply create an `IndeedScraper` class that adheres to the same interface without changing the orchestrator.
-   **Implementation:** We will define a `Scraper` base class and have our `LinkedInScraper` inherit from it.

## 3. Error Handling & Reliability

### 3.1. Circuit Breaker Pattern

-   **Component:** `Scraping Module` and `Telegram Notifier`
-   **Reasoning:** When interacting with external APIs (like LinkedIn or Telegram), failures can be temporary or persistent. The Circuit Breaker pattern prevents the application from repeatedly trying an operation that is likely to fail.
-   **Implementation:** If the LinkedIn scraper fails (e.g., due to a UI change), the circuit will "trip," and the application will stop and send an alert instead of retrying fruitlessly. We can use a library like `pybreaker` to implement this, or a simpler custom implementation with a state machine (CLOSED, OPEN, HALF-OPEN).

### 3.2. Retry Pattern

-   **Component:** `Content Generation Agent`
-   **Reasoning:** LLM calls can occasionally fail due to transient network issues or temporary API overloads. Instead of failing the entire process, we should retry the operation a few times.
-   **Implementation:** The call to the LLM API within the Content Generation Agent will be wrapped in a retry loop (e.g., using the `tenacity` library) that will attempt the call up to 3 times with an exponential backoff before finally failing. 